# Сводная статистика
Подробный анализ кодовой базы каждого репозитория приведен в отдельном файле. 
 
На основании имеющейся кодовой базы, можно сделать следующий анализ
## Распределение технологий
- Go: 6 репозиториев
- Java: 2 репозитория
- JavaScript/Node.js: 3 репозитория
- Rust: 1 репозиторий
- C# .NET: 1 репозиторий
- Python: 1 репозиторий

## Распределение по уровню экспертизы
- Senior level: 8 репозиториев (62%)
- Middle level: 1 репозиторий (8%)
- Jun to Middle: 3 репозитория (23%)
- Junior level: 1 репозиторий (7%)

## Ключевые выводы
- Доминирование Go: 6 из 13 активных репозиториев выбрали Go, что указывает на его популярность в бэкенд-разработке на хакатонах
- Корпоративный фокус Java: Оба Java-проекта (mnp, NPE) демонстрируют архитектуру корпоративного уровня с Spring Boot
- Высокопроизводительные решения: Проекты как zulu и rorobotics показывают фокус на производительность и стресс-тестирование
- Преобладание старшего уровня: 62% активных проектов демонстрируют практики кодирования старшего уровня
- Командная работа: Проекты вроде metaload-akbori, alem и NPE демонстрируют отличные рабочие процессы с несколькими участниками
- Фокус на архитектуре: Большинство команд отдали приоритет правильным архитектурным шаблонам над быстрыми прототипами

# Результаты команд
- HelloAlem - 325 баллов
- Rorobotics - 301 балл
- Metaload - 296 баллов
- Bulbul - 281 балл

## Критерии оценки команд
- Код в репозитории - 100 баллов
  - Решение развернуто и доступны все методы API - 30 баллов максимум
- Пройдены тесты на поиск событий, под нагрузкой:
  - 1000 rps - 10 баллов
  - 5000 rps - 20 баллов
  - 10000 rps - 30 баллов
- Поиск по архивным событиям
  - 1000 rps - 10 баллов
  - 5000 rps - 20 баллов
  - 10000 rps - 30 баллов
- Реализован функционал бронирования билетов
  - 1000 rps - 10 баллов
  - 5000 rps - 20 баллов
  - 10000 rps - 30 баллов
- Потраченный средства на решение - Максимум 30 баллов. Чем меньше потрачено - тем ближе к 30 баллам. 

# Описание решений команд
Видео-версия доступна [тут](https://www.youtube.com/live/OwZcXAnd0xM?si=D2x71TN5mJT2Medc).

## Команда Rorobotics
[Код команды](https://github.com/hackload-kz/rorobotics)

### Участники
- Дмитрий Романов, Павлодар

### Решение
Билетная система с акцентом на качественный код и архитектуру. Монолитное решение в контейнере с фокусом на производительность.
Решение выдержало нагрузку в 25000 rps

### Технологии
- Backend: Rust
- База данных: PostgreSQL с Redis для кэширования и атомарности операций
- Архитектура: Монолитная структура, похожая на Laravel
- Инфраструктура: Один виртуальный сервер 16 ГБ RAM, 16 ГБ CPU

### Сложности
- Работа в одиночку - сложно довести все до конца
- Язык Rust не родной для участника
- Много времени ушло на документирование кода для понимания другими

### Особенности решения
- Нетрадиционная архитектура для Rust-проектов
- Структура больше похожа на Laravel
- Качественно документированный код с множеством комментариев
- "Скрестил два мира" - Rust с Laravel-подобной структурой

## Команда HelloAlem
[Код команды](https://github.com/hackload-kz/alem)

### Участники
- Алимухамед Тлекбаи, Астана 
- Абылайхан Зулбухаров, Астана
- Диас Каппассов, Астана

### Решение
Система бронирования билетов с упором на производительность и простую архитектуру.
Решение выдержало нагрузку в 25000 rps

### Технологии
- Backend: Go (Golang)
- Веб-сервер: Nginx (reverse proxy, SSL termination)
- База данных: SQLite 3
- Очереди: RiverQueue для асинхронных джобов
- Инфраструктура: Один виртуальный сервер 16 ГБ RAM, 16 ГБ CPU
- Кодогенерация: OAPI для серверов и клиентов, SQLC для SQL запросов

### Сложности
- Разбор сложных требований – половина времени ушла на понимание ТЗ
- Отлично задокументировано решение
- Тюнинг SQLite 3 - изначально только 7,000 RPS, после оптимизации достигли 20,000 RPS
- Проблемы с сетью – локально высокая производительность, удаленно ограничения сети
- Настройка Nginx как bottleneck

### Особенности решения
- Самый лучший пример документирования решения
- SQLite быстрее Redis из-за отсутствия сетевых вызовов (все локально)
- Использование SQLite FTS5 для full-text search
- Команда Reset оптимизирована с 20 секунд до 2 секунд через Go routines и каналы
- Достижение sub-millisecond latency на 95-м процентиле
- Использование диаграмм Mermaid и DeepWiki для понимания требований


## Команда Bulbul
[Код команды](https://github.com/hackload-kz/Bulbul)

### Участники
- Bolat Kazybayev, Алматы
- Serik Shaikamalov, Алматы
- Nurmyshev Serik, Астана
- Raimbek, Шымкент

### Решение
Микросервисная архитектура с акцентом на инфраструктуру и масштабируемость.
Решение выдержало нагрузку в 10000 rps (не тестировалось на 25000 rps)

### Технологии
- Backend: Go с веб-фреймворком Gene
- Load Balancer: Nginx с настройкой LeastConnection
- Кэш: Valkyrie (форк Redis) с client-side caching
- База данных: PostgreSQL + Elasticsearch для full-text search
- Мониторинг: Prometheus + Grafana
- Инфраструктура: Terraform + Ansible для деплоя
- Профилирование: Go профайлер

### Сложности
- PostgreSQL full-text search работал плохо (100% CPU на 50 пользователях)
- MongoDB тоже показал плохую производительность для full-text search
- Настройка IP local port range в Linux (ошибка "cannot assign requested address")
- Большие расходы на инфраструктуру в начале

### Особенности решения
- Client-side caching в Valkyrie - значительно улучшило показатели latency
- Условное кэширование только для запросов с page/pageSize кратными 5
- Оптимизация JSON обработки - исключение лишних Marshal/Unmarshal операций
- Elasticsearch справился с 5,000 пользователями (20-25 секунд latency)
- Автоматизация через Cloud Code для Ansible ролей и Grafana дашбордов

## Команда Metaload
[Код команды](https://github.com/hackload-kz/metaload-akbori)

### Участники
- Dauren, Астана
- Диас, Астана
- Дармен, Астана
- Баят, Астана

### Решение
Система билетного сервиса с применением Domain-Driven Design и современных архитектурных паттернов.

### Технологии
- Backend: Изначально Java (Spring Boot), затем переписали на Go
- База данных: PostgreSQL с Event Sourcing и CQRS
- Очереди: Apache Kafka
- Кэш: Redis
- Load Balancer: Nginx
- Архитектура: Порты и адаптеры (Hexagonal Architecture)
- Тестирование: Test Driven Development (TDD)
- Мониторинг: Zero Code Instrumentation для телеметрии

### Сложности
- Java приложение не выдержало первый тест (доходило до 5 ГБ памяти и падало)
- Управление расходами в облаке - изначально много серверов сжигали бюджет
- Недостаток DevOps навыков в команде
- Лаги между read и проекцией через CQRS из-за ограниченных ресурсов
- Сложности с пониманием требований (смысл submit операции)

### Особенности решения
- Переход с Java на Go показал кардинальное улучшение производительности
- Event Sourcing + CQRS - события хранятся в одной таблице, состояние восстанавливается
- Rich Domain Model с использованием DDD принципов
- Test Driven Development для быстрой реализации доменной модели
- Минимальные зависимости в Java версии (без Spring/Hibernate)
- Стратегия предварительного бронирования мест перед оплатой

# Команды, которые не добрались до финиша, но заслуживают внимания

## MNP 
[код в репозитории](https://github.com/hackload-kz/mnp)

Команда продемонстрировала хорошие инженерные практики с архитектурой микросервисов, комплексной настройкой тестирования и правильным мониторингом, но столкнулась с типичными для хакатона проблемами интеграции, конфигурации и отладки в условиях временного давления.

### Участникни
- Батир Кенжаев
- Ермагомбет Дархан
- Махатов Жасулан
- aluad
- sultan

### Используемые технологии
- Backend: Spring Boot 3.5.4, Java 21
- Архитектура: Микросервисы (5 модулей: biletter, payment-gateway-integration, ticketing-service-provider-integration, admin, gatling)
- База данных: Spring Data JPA с сущностями для бронирований, событий, мест, пользователей
- Интеграция: OpenFeign для связи с внешними сервисами
- Безопасность: Spring Security с OAuth2
- Документация: Swagger/OpenAPI 3
- Кэширование: Spring Cache
- Инфраструктура: Docker, SSL сертификаты, docker-compose
- Нагрузочное тестирование: Gatling с 80k+ тестовых событий и 6480+ тестовых пользователей
- Мониторинг: Spring Boot Admin

### Где команда столкнулась с трудностями

- Проблемы с кэшированием
  - Проблемы с аутентификацией. Проблемы конфигурации безопасности
  - Конфигурация базы данных. Проблемы со свойствами приложения и автокоммитом
  - Баги управления местами. Проблемы с логикой выбора/статуса мест
  - Проблемы интеграции Feign клиентов - Множественные коммиты для налаживания связи с внешними сервисами
  - Структура репозитория и сущностей - Пришлось несколько раз рефакторить слой данных
- Проблемы производительности:
  - Добавили обширное нагрузочное тестирование с Gatling - предполагает, что они ожидали или столкнулись с проблемами производительности
  - Реализация кэширования добавлена в середине разработки - вероятно, в ответ на проблемы производительности
  - Добавлена обработка исключений и логика повторных попыток для вызовов внешних сервисов

## Zulu
[Код в репозитории](https://github.com/hackload-kz/zulu)

Данная команда заслуживает особого внимания, поскольку сделали попытке реализовать решение с использованием технологий blockchain. Ниже перевод выводов команды из их репозитория.

### Первоначальное исследование блокчейна
Изначально мы решили изучить технологию блокчейна для реализации нашей билетной системы, несмотря на понимание того, что специализированные фреймворки, вероятно, превзойдут блокчейн-решения в сценариях высокой нагрузки. Мы хотели увидеть реальную разницу в метриках производительности по сравнению с другими реализациями, представленными на хакатоне.
Наша гипотеза заключалась в том, что преимущества блокчейна в одноранговых сетях могут оправдать его использование по мере масштабирования сети с большим количеством участников.

#### Часть 1: Исследование Solana
Наша первая попытка включала развертывание частного кластера Solana. Однако мы быстро выявили проблемы с архитектурным дизайном Solana, особенно его историю инцидентов с отказом в обслуживании, которые не затронули более устоявшиеся сети, такие как Bitcoin и Ethereum. Это привело нас к изучению альтернативных блокчейн-платформ.

#### Часть 2: Проблемы с Hyperledger Fabric
Затем мы исследовали Hyperledger Fabric как решение разрешенного блокчейна, которое казалось идеальным для наших корпоративных требований к билетной системе. Однако развертывание оказалось сложнее, чем ожидалось:
Корпоративная сложность: Платформа требует обширной технической экспертизы сверх обычной настройки публичного блокчейна
Ограниченная экосистема: По сравнению с Ethereum документация была скудной, а поддержка сообщества минимальной
Проблемы с инструментами: Многообещающие инструменты, такие как "minifabric" (развертывание кластера с одной конфигурацией), были заброшены, в то время как альтернативы, такие как "microfabric", не работали в нашей локальной среде

#### Часть 3: Исследование специфичных для приложений блокчейнов
Мы также оценили специфичные для приложений блокчейн-фреймворки, такие как Tendermint и CosmosSDK. Хотя они многообещающие, эти платформы не поддерживают JavaScript для пользовательской бизнес-логики, требуя экспертизы в Go, которой у нас не было в рамках временных ограничений.
Переход к разработке с помощью ИИ
Осознав временные ограничения для настройки блокчейна, мы переключились на изучение методологий разработки с помощью ИИ, используя этот хакатон как возможность поэкспериментировать с современными практиками разработки.
Методология разработки
Разработка, управляемая PRD: Использовали детальные документы требований к продукту для руководства реализацией
TDD с помощью ИИ: Экспериментировали с разработкой через тестирование, усиленной ассистентами ИИ для кодирования

Инструменты: Использовали OpenCode и Claude Code для разработки Node.js API в соответствии со спецификациями

### Результаты реализации
Этот подход позволил нам успешно реализовать:
- Billetter API: Полный сервис билетной системы с управлением событиями, резервированием мест и интеграцией платежей
- Event Provider Service: Обертка внешнего API для распределенных билетных сетей
- Комплексное тестирование: Модульные, интеграционные и нагрузочные тесты, подтверждающие требования к производительности
- Готовая к продакшену архитектура: Сервис-ориентированный дизайн, поддерживающий нагрузки корпоративного масштаба
- Журнал разработки и извлеченные уроки

### Технические достижения
- Быстрое прототипирование: Разработка с помощью ИИ значительно ускорила первоначальную реализацию
- Покрытие тестами: Достигли комплексного тестирования, включая валидацию производительности
- Качество архитектуры: Предоставили готовые к продакшену абстракции и паттерны сервисов
- Соответствие спецификациям: Полное соблюдение требований OpenAPI

### Ключевые выводы
- Сложность блокчейна: Развертывание корпоративного блокчейна требует значительных временных инвестиций и специализированной экспертизы
- Разработка с ИИ: Современные инструменты ИИ могут эффективно ускорить разработку при сочетании с твердым архитектурным планированием
- PRD-подход: Детальные документы требований обеспечивают более сфокусированную и эффективную разработку
- Тестирование в первую очередь: Разработка нагрузочных тестов параллельно с основным функционалом обеспечивает достижение целей производительности

### Будущие соображения по блокчейну
- Хотя мы не завершили реализацию блокчейна в рамках временных ограничений хакатона, мы определили многообещающие пути для будущего исследования:
- CosmosSDK: Может быть идеальным для специфичных для приложений билетных цепей с ресурсами разработки Go/Rust
- Hyperledger Fabric: Остается жизнеспособным для корпоративных развертываний при наличии соответствующей экспертизы в настройке
- Гибридный подход: Традиционное высокопроизводительное ядро с интеграцией блокчейна для конкретных случаев использования (аудиторские следы, многосторонняя координация)